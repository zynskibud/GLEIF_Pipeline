{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this function will be in a seperate class which is responsible for obtaining the download links for each set of GLEIF data. That way each script can take care of and process the data invidually, but the same function logic for grabbing a link would not have to be repeated in each script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyvis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msqlite3\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzipfile\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetwork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Network\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyvis'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import requests\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import sqlite3\n",
    "import zipfile\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import urllib.parse\n",
    "\n",
    "class GLEIF_Data_Helpers:\n",
    "    def __init__(self, bool_Level_1 = False, bool_Level_2_Trees = False, bool_Level_2_Reporting_Exceptions = False):\n",
    "        self.bool_Level_1 = bool_Level_1\n",
    "        self.bool_Level_2_Trees = bool_Level_2_Trees\n",
    "        self.bool_Level_2_Reporting_Exceptions = bool_Level_2_Reporting_Exceptions\n",
    "\n",
    "    def get_level_download_links(self):\n",
    "        \"\"\"\n",
    "        This function uses selenium to webscrape the download link for all Level 1 Data in the GLEIF database.\n",
    "        \n",
    "        @return: str_download_link - the link which is used to download the entire GLEIF level 1\n",
    "        \"\"\"\n",
    "        #Maybe new function\n",
    "\n",
    "        driver_path = (r\"C:\\Drivers\\Google\\chromedriver-win64\\chromedriver-win64\\chromedriver.exe\")\n",
    "        service = Service(driver_path)\n",
    "        driver = webdriver.Chrome(service=service)\n",
    "        driver.get(url = \"https://www.gleif.org/en/lei-data/gleif-golden-copy/download-the-golden-copy#/\")\n",
    "\n",
    "        cookie_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, 'CybotCookiebotDialogBodyButton'))\n",
    "        )\n",
    "\n",
    "        cookie_button.click()\n",
    "\n",
    "        download_buttons = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, 'gc-download-button'))\n",
    "        )\n",
    "        \n",
    "        if self.bool_Level_1 == True:\n",
    "            download_buttons[0].click()\n",
    "        if self.bool_Level_2_Trees == True:\n",
    "            download_buttons[1].click()\n",
    "        if self.bool_Level_2_Reporting_Exceptions == True:\n",
    "            download_buttons[2].click()\n",
    "        \n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "        driver.close()\n",
    "\n",
    "        str_download_link = ((soup.find_all(\"a\" , class_ = \"gc-icon gc-icon--json\"))[0])[\"href\"]\n",
    "        \n",
    "        return str_download_link        \n",
    "    \n",
    "    def create_sql_instance(self, str_db_name, str_table_name):\n",
    "        # Connect to the SQLite database with WAL mode enabled\n",
    "        conn = sqlite3.connect(f'{str_db_name}.db', timeout=10)  # Set a timeout for waiting on locks\n",
    "        conn.execute('PRAGMA journal_mode=WAL;')  # Enable WAL mode for concurrency\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Create the table with an id and JSON field (storing JSON as TEXT)\n",
    "        cursor.execute(f'''\n",
    "        CREATE TABLE IF NOT EXISTS {str_table_name} (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        data TEXT\n",
    "        )\n",
    "        ''')\n",
    "        \n",
    "        return conn, cursor\n",
    "    \n",
    "    def unpacking_GLEIF_zip_files(self , str_download_link , str_zip_file_path , str_unpacked_zip_file_path):\n",
    "        session = requests.Session()\n",
    "        zip_file = session.get(url = str_download_link)\n",
    "\n",
    "        with open(str_zip_file_path, 'wb') as f:\n",
    "            f.write(zip_file.content)\n",
    "\n",
    "        with zipfile.ZipFile(str_zip_file_path, 'r') as zip_ref:\n",
    "            os.makedirs(str_unpacked_zip_file_path, exist_ok=True)\n",
    "            zip_ref.extractall(str_unpacked_zip_file_path)\n",
    "        \n",
    "        str_unpacked_zip_file_name = os.listdir(str_unpacked_zip_file_path)[0]\n",
    "        str_json_file_path = str_unpacked_zip_file_path + \"\\\\\" + str_unpacked_zip_file_name\n",
    "        \n",
    "        return str_json_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the backend logic which produces a list of graphs, where each element represents a company ecosystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import bigjson\n",
    "import sqlite3\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "class GLEIFLevel2Data:\n",
    "    def __init__(self):\n",
    "        self.str_level_2_unpacked_zip_file_path = r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\Zip_Files\\GLEIF\\Level_2_Data\\RR_CDF_Data\\Unpacked_Zip\"\n",
    "        self.str_level_2_zip_file_path = r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\Zip_Files\\GLEIF\\Level_2_Data\\RR_CDF_Data\\.Level_2_RR_CDF.zip\"\n",
    "        self.obj_data_helpers = GLEIF_Data_Helpers(bool_Level_2_Trees = True)\n",
    "\n",
    "    def insert_json_data(self, json_data , conn , cursor , str_table_name):\n",
    "        cursor.execute(f'''\n",
    "        INSERT INTO {str_table_name}  (data)\n",
    "        VALUES (?)\n",
    "        ''', (json.dumps(json_data),))\n",
    "        conn.commit()\n",
    "    \n",
    "    def storing_GLEIF_data_in_database(self):\n",
    "        str_level_2_download_link = self.obj_data_helpers.get_level_download_links()\n",
    "        str_json_file_path = self.obj_data_helpers.unpacking_GLEIF_zip_files(str_download_link = str_level_2_download_link , str_zip_file_path = self.str_level_2_zip_file_path , str_unpacked_zip_file_path = self.str_level_2_unpacked_zip_file_path)\n",
    "        conn, cursor = self.obj_data_helpers.create_sql_instance(str_table_name = \"Level_2_Tree_Data\" , str_db_name = \"GLEIF_Data\")\n",
    "        \n",
    "        \"\"\"with open(str_json_file_path, 'r', encoding='utf-8') as file:\n",
    "            # Read the file content\n",
    "            json_content = file.read()  # Read the entire file content as a string\n",
    "            \n",
    "            # Print the first 50,000 characters\n",
    "            print(json_content[:50000])\"\"\"\n",
    "        \n",
    "        with open(str_json_file_path, 'r' , encoding='utf-8') as file:\n",
    "            test = bigjson.load(file)\n",
    "            #counter = 1\n",
    "            for dict_lei in test[\"relations\"]:\n",
    "                #if counter != 15000:\n",
    "                self.insert_json_data(json_data = dict_lei.to_python() , conn = conn , cursor = cursor , str_table_name = \"Level_2_Tree_Data\")\n",
    "                    #counter += 1\n",
    "                #else:\n",
    "                    #break\"\"\"\n",
    "        \n",
    "        conn.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyvis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyvis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnetwork\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Network\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyvis'"
     ]
    }
   ],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import urllib.parse\n",
    "\n",
    "def visualize_graph_interactive_html(G: nx.DiGraph, title: str = 'Interactive_Graph') -> str:\n",
    "    \"\"\"\n",
    "    Visualizes the graph using PyVis and returns the HTML content as a string.\n",
    "    \n",
    "    :param G: The NetworkX directed graph to visualize.\n",
    "    :param title: The title of the graph.\n",
    "    :return: HTML string of the interactive graph.\n",
    "    \"\"\"\n",
    "    # Initialize PyVis Network with remote CDN resources for better compatibility\n",
    "    net = Network(notebook=False, directed=True, height='750px', width='100%', cdn_resources='remote')\n",
    "    \n",
    "    # Add nodes with titles\n",
    "    for node, data in G.nodes(data=True):\n",
    "        label = node\n",
    "        title_text = (\n",
    "            f\"Node: {node}<br>\"\n",
    "            f\"Parents: {len(data.get('parent_relationships', {}))}<br>\"\n",
    "            f\"Children: {len(data.get('child_relationships', {}))}\"\n",
    "        )\n",
    "        net.add_node(node, label=label, title=title_text)\n",
    "    \n",
    "    # Add edges\n",
    "    for source, target in G.edges():\n",
    "        net.add_edge(source, target)\n",
    "    \n",
    "    # Customize physics for better layout\n",
    "    net.show_buttons(filter_=['physics'])\n",
    "    net.toggle_physics(True)\n",
    "    \n",
    "    # Generate HTML as a string\n",
    "    try:\n",
    "        html_content = net.generate_html()\n",
    "        print(f\"Interactive graph '{title}' generated successfully.\")\n",
    "        return html_content\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating the interactive graph: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def display_html_in_browser(html_content: str):\n",
    "    \"\"\"\n",
    "    Displays the given HTML content in a web browser using Selenium and keeps the browser open.\n",
    "    \n",
    "    :param html_content: The HTML content to display.\n",
    "    \"\"\"\n",
    "    if not html_content:\n",
    "        print(\"No HTML content to display.\")\n",
    "        return\n",
    "    \n",
    "    # Encode the HTML content for use in a data URL\n",
    "    encoded_html = urllib.parse.quote(html_content)\n",
    "    data_url = f\"data:text/html;charset=utf-8,{encoded_html}\"\n",
    "    \n",
    "    # Setup Selenium WebDriver (Chrome in this example)\n",
    "    try:\n",
    "        # Initialize Chrome WebDriver using webdriver_manager for automatic driver management\n",
    "        service = ChromeService(ChromeDriverManager().install())\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"--start-maximized\")  # Optional: start maximized\n",
    "        options.add_experimental_option(\"detach\", True)  # Keep the browser open after script ends\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        \n",
    "        # Open the data URL\n",
    "        driver.get(data_url)\n",
    "        \n",
    "        #print(\"Interactive graph opened in the browser.\")\n",
    "        \n",
    "        # Optional: Keep the script running to maintain the WebDriver session\n",
    "        # Uncomment the following lines if you prefer the browser to stay open until you manually close it\n",
    "        # import time\n",
    "        # while True:\n",
    "        #     time.sleep(10)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error opening the interactive graph in the browser: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "import networkx as nx\n",
    "from typing import List, Dict, Optional, Set\n",
    "from datetime import datetime\n",
    "\n",
    "# Define relationship types and categorize them\n",
    "class RelationshipType:\n",
    "    DIRECT = 'IS_DIRECTLY_CONSOLIDATED_BY'\n",
    "    ULTIMATE = 'IS_ULTIMATELY_CONSOLIDATED_BY'\n",
    "    BRANCH = 'IS_INTERNATIONAL_BRANCH_OF'\n",
    "    SUBFUND = 'IS_SUBFUND_OF'\n",
    "    FEEDER = 'IS_FEEDER_TO'\n",
    "    FUND_MANAGED = 'IS_FUND-MANAGED_BY'\n",
    "\n",
    "    DIRECT_RELATIONSHIPS = {DIRECT}\n",
    "    ULTIMATE_RELATIONSHIPS = {ULTIMATE}\n",
    "    OTHER_RELATIONSHIPS = {BRANCH, SUBFUND, FEEDER, FUND_MANAGED}\n",
    "\n",
    "def relationship_list_generator():\n",
    "        list_rows = []\n",
    "        \n",
    "        conn = sqlite3.connect(r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\B_Notebooks\\GLIEF_company_data_pipeline\\GLEIF_Data.db\", check_same_thread=False)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute('SELECT data FROM Level_2_Tree_Data')\n",
    "        \n",
    "        rows = cursor.fetchall()\n",
    "        \n",
    "        for row in rows:\n",
    "            json_text = row[0]  # Get the JSON text from the tuple\n",
    "            json_dict = json.loads(json_text)  # Parse JSON text into a dictionary\n",
    "            list_relationship = [json_dict[\"RelationshipRecord\"][\"Relationship\"][\"StartNode\"][\"NodeID\"][\"$\"] , json_dict[\"RelationshipRecord\"][\"Relationship\"][\"EndNode\"][\"NodeID\"][\"$\"] , json_dict[\"RelationshipRecord\"][\"Relationship\"][\"RelationshipType\"][\"$\"] , json_dict[\"RelationshipRecord\"][\"Relationship\"][\"RelationshipStatus\"][\"$\"] , json_dict[\"RelationshipRecord\"][\"Registration\"][\"RegistrationStatus\"][\"$\"] , json_dict[\"RelationshipRecord\"][\"Registration\"][\"InitialRegistrationDate\"][\"$\"] , json_dict[\"RelationshipRecord\"][\"Registration\"][\"LastUpdateDate\"][\"$\"] , json_dict[\"RelationshipRecord\"][\"Registration\"][\"NextRenewalDate\"][\"$\"]]\n",
    "            list_rows.append(list_relationship) # Add the dictionary to the list\n",
    "            \n",
    "        conn.close()\n",
    "        \n",
    "        return list_rows\n",
    "\n",
    "def create_relationship_dict(relationship_type, relationship_status, registration_status, initial_registration_date, last_update_date, next_renewal_date):\n",
    "    \"\"\"\n",
    "    Creates a dictionary containing all attributes of a relationship.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'relationship_type': relationship_type,\n",
    "        'relationship_status': relationship_status,\n",
    "        'registration_status': registration_status,\n",
    "        'initial_registration_date': initial_registration_date,\n",
    "        'last_update_date': last_update_date,\n",
    "        'next_renewal_date': next_renewal_date\n",
    "    }\n",
    "\n",
    "def build_graph(relationships: List[List[str]], relationship_types_to_include: Optional[Set[str]] = None) -> nx.DiGraph:\n",
    "    \"\"\"\n",
    "    Builds a directed graph from the list of relationships,\n",
    "    adding relationship attributes directly to the nodes.\n",
    "\n",
    "    :param relationships: List of relationships, each represented as a list\n",
    "    :param relationship_types_to_include: Optional set of relationship types to include.\n",
    "    :return: A networkx DiGraph representing the company relationships\n",
    "    \"\"\"\n",
    "    G = nx.DiGraph()\n",
    "    G_direct = nx.DiGraph()\n",
    "\n",
    "    # If no specific relationship types are provided, include all\n",
    "    if relationship_types_to_include is None:\n",
    "        relationship_types_to_include = {\n",
    "            RelationshipType.DIRECT,\n",
    "            RelationshipType.ULTIMATE,\n",
    "            *RelationshipType.OTHER_RELATIONSHIPS\n",
    "        }\n",
    "\n",
    "    display(relationship_types_to_include)\n",
    "    \n",
    "    direct_relationships = []\n",
    "    ultimate_relationships = []\n",
    "    other_relationships = []\n",
    "\n",
    "    # Separate relationships into direct, ultimate, and others based on the types to include\n",
    "    for rel in relationships:\n",
    "        relationship_type = rel[2]\n",
    "        if relationship_type not in relationship_types_to_include:\n",
    "            continue  # Skip relationships not in the specified types\n",
    "        if relationship_type == RelationshipType.DIRECT:\n",
    "            direct_relationships.append(rel)\n",
    "        elif relationship_type == RelationshipType.ULTIMATE:\n",
    "            ultimate_relationships.append(rel)\n",
    "        elif relationship_type in RelationshipType.OTHER_RELATIONSHIPS:\n",
    "            other_relationships.append(rel)\n",
    "        else:\n",
    "            # Handle unknown relationship types if necessary\n",
    "            other_relationships.append(rel)\n",
    "\n",
    "    # Initialize node attributes\n",
    "    for rel in relationships:\n",
    "        child_lei, parent_lei, _, _, _, _, _, _ = rel\n",
    "        # Initialize child node if not present\n",
    "        if child_lei not in G.nodes:\n",
    "            G.add_node(child_lei, child_relationships={}, parent_relationships={})\n",
    "        # Initialize parent node if not present\n",
    "        if parent_lei not in G.nodes:\n",
    "            G.add_node(parent_lei, child_relationships={}, parent_relationships={})\n",
    "\n",
    "    # Add direct relationships to both G and G_direct\n",
    "    for rel in direct_relationships:\n",
    "        child_lei, parent_lei, relationship_type, relationship_status, registration_status, \\\n",
    "        initial_registration_date, last_update_date, next_renewal_date = rel\n",
    "\n",
    "        # Add nodes to G_direct (already added to G)\n",
    "        G_direct.add_node(child_lei)\n",
    "        G_direct.add_node(parent_lei)\n",
    "\n",
    "        # Add edge to G and G_direct\n",
    "        G.add_edge(child_lei, parent_lei)\n",
    "        G_direct.add_edge(child_lei, parent_lei)\n",
    "\n",
    "        # Create relationship dictionary\n",
    "        relationship_dict = create_relationship_dict(\n",
    "            relationship_type, relationship_status, registration_status,\n",
    "            initial_registration_date, last_update_date, next_renewal_date\n",
    "        )\n",
    "\n",
    "        # Update node attributes in G\n",
    "        G.nodes[child_lei]['parent_relationships'].setdefault(parent_lei, []).append(relationship_dict)\n",
    "        G.nodes[parent_lei]['child_relationships'].setdefault(child_lei, []).append(relationship_dict)\n",
    "\n",
    "    # Add other relationships (non-direct, non-ultimate) only to G\n",
    "    for rel in other_relationships:\n",
    "        child_lei, parent_lei, relationship_type, relationship_status, registration_status, \\\n",
    "        initial_registration_date, last_update_date, next_renewal_date = rel\n",
    "\n",
    "        # Add edge to G\n",
    "        G.add_edge(child_lei, parent_lei)\n",
    "\n",
    "        # Create relationship dictionary\n",
    "        relationship_dict = create_relationship_dict(\n",
    "            relationship_type, relationship_status, registration_status,\n",
    "            initial_registration_date, last_update_date, next_renewal_date\n",
    "        )\n",
    "\n",
    "        # Update node attributes in G\n",
    "        G.nodes[child_lei]['parent_relationships'].setdefault(parent_lei, []).append(relationship_dict)\n",
    "        G.nodes[parent_lei]['child_relationships'].setdefault(child_lei, []).append(relationship_dict)\n",
    "\n",
    "    # Process ultimate relationships\n",
    "    for rel in ultimate_relationships:\n",
    "        child_lei, ultimate_parent_lei, relationship_type, relationship_status, registration_status, \\\n",
    "        initial_registration_date, last_update_date, next_renewal_date = rel\n",
    "\n",
    "        # Add nodes to G_direct (already added to G)\n",
    "        G_direct.add_node(child_lei)\n",
    "        G_direct.add_node(ultimate_parent_lei)\n",
    "\n",
    "        # Check if a direct edge exists\n",
    "        direct_edge_exists = G_direct.has_edge(child_lei, ultimate_parent_lei)\n",
    "\n",
    "        if direct_edge_exists:\n",
    "            # Direct edge exists; ultimate relationship is NOT redundant\n",
    "            # Add edge to G\n",
    "            G.add_edge(child_lei, ultimate_parent_lei)\n",
    "\n",
    "            # Create relationship dictionary\n",
    "            relationship_dict = create_relationship_dict(\n",
    "                relationship_type, relationship_status, registration_status,\n",
    "                initial_registration_date, last_update_date, next_renewal_date\n",
    "            )\n",
    "\n",
    "            # Update node attributes in G\n",
    "            G.nodes[child_lei]['parent_relationships'].setdefault(ultimate_parent_lei, []).append(relationship_dict)\n",
    "            G.nodes[ultimate_parent_lei]['child_relationships'].setdefault(child_lei, []).append(relationship_dict)\n",
    "        else:\n",
    "            # Check if a path exists via direct relationships excluding direct edge\n",
    "            if nx.has_path(G_direct, child_lei, ultimate_parent_lei):\n",
    "                # Path exists via other nodes; ultimate relationship is redundant\n",
    "                continue\n",
    "            else:\n",
    "                # No path exists; add edge to G\n",
    "                G.add_edge(child_lei, ultimate_parent_lei)\n",
    "\n",
    "                # Create relationship dictionary\n",
    "                relationship_dict = create_relationship_dict(\n",
    "                    relationship_type, relationship_status, registration_status,\n",
    "                    initial_registration_date, last_update_date, next_renewal_date\n",
    "                )\n",
    "\n",
    "                # Update node attributes in G\n",
    "                G.nodes[child_lei]['parent_relationships'].setdefault(ultimate_parent_lei, []).append(relationship_dict)\n",
    "                G.nodes[ultimate_parent_lei]['child_relationships'].setdefault(child_lei, []).append(relationship_dict)\n",
    "\n",
    "    return G\n",
    "\n",
    "def extract_company_ecosystems(G: nx.DiGraph) -> List[nx.DiGraph]:\n",
    "    \"\"\"\n",
    "    Extracts ecosystems (connected components) from the graph.\n",
    "\n",
    "    :param G: The graph to extract ecosystems from\n",
    "    :return: A list of subgraphs, each representing a company ecosystem\n",
    "    \"\"\"\n",
    "    # Convert to undirected graph to find connected components\n",
    "    UG = G.to_undirected()\n",
    "\n",
    "    # Find connected components\n",
    "    connected_components = list(nx.connected_components(UG))\n",
    "\n",
    "    # Extract subgraphs for each component\n",
    "    ecosystems = []\n",
    "    for component in connected_components:\n",
    "        # Create subgraph\n",
    "        subgraph = G.subgraph(component).copy()\n",
    "        ecosystems.append(subgraph)\n",
    "\n",
    "    return ecosystems\n",
    "\n",
    "def create_leis_to_graph(ecosystems: List[nx.DiGraph]) -> Dict[str, nx.DiGraph]:\n",
    "    \"\"\"\n",
    "    Creates a dictionary mapping each LEI (node) to its corresponding ecosystem graph.\n",
    "\n",
    "    :param ecosystems: List of NetworkX DiGraph objects, each representing a company ecosystem.\n",
    "    :return: Dictionary with LEI as keys and their corresponding DiGraph as values.\n",
    "    \"\"\"\n",
    "    leis_to_graph = {}\n",
    "    for graph in ecosystems:\n",
    "        for node in graph.nodes():\n",
    "            leis_to_graph[node] = graph\n",
    "    return leis_to_graph\n",
    "\n",
    "def graph_processor(include_company_relationships: bool = True, include_fund_relationships: bool = True):\n",
    "    \"\"\"\n",
    "    Main function to build the graph and extract company ecosystems.\n",
    "\n",
    "    :param include_company_relationships: Boolean flag to include company relationships (direct and ultimate).\n",
    "    :param include_fund_relationships: Boolean flag to include fund relationships.\n",
    "    :return: List of company ecosystem subgraphs and mapping from LEI to graphs.\n",
    "    \"\"\"\n",
    "    # Build the overall graph with node attributes\n",
    "    list_relationships = relationship_list_generator()\n",
    "\n",
    "    # Build the set of relationship types to include\n",
    "    relationship_types_to_include = set()\n",
    "\n",
    "    if include_company_relationships:\n",
    "        relationship_types_to_include.update({RelationshipType.DIRECT, RelationshipType.ULTIMATE})\n",
    "\n",
    "    if include_fund_relationships:\n",
    "        relationship_types_to_include.update(RelationshipType.OTHER_RELATIONSHIPS)\n",
    "\n",
    "    if not relationship_types_to_include:\n",
    "        # If no relationships are included, default to including all relationships\n",
    "        relationship_types_to_include.update({\n",
    "            RelationshipType.DIRECT,\n",
    "            RelationshipType.ULTIMATE,\n",
    "            *RelationshipType.OTHER_RELATIONSHIPS\n",
    "        })\n",
    "\n",
    "    G = build_graph(list_relationships, relationship_types_to_include)\n",
    "\n",
    "    # Extract company ecosystems\n",
    "    ecosystems = extract_company_ecosystems(G)        \n",
    "\n",
    "    leis_to_graph = create_leis_to_graph(ecosystems=ecosystems)\n",
    "\n",
    "    return ecosystems, leis_to_graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_relationships = relationship_list_generator()\n",
    "display(type(list_relationships))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "no such table: Level_2_Tree_Data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ecosystems, dict_leis_graph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 236\u001b[0m, in \u001b[0;36mgraph_processor\u001b[1;34m(include_company_relationships, include_fund_relationships)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;124;03mMain function to build the graph and extract company ecosystems.\u001b[39;00m\n\u001b[0;32m    230\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m:return: List of company ecosystem subgraphs and mapping from LEI to graphs.\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;66;03m# Build the overall graph with node attributes\u001b[39;00m\n\u001b[1;32m--> 236\u001b[0m list_relationships \u001b[38;5;241m=\u001b[39m \u001b[43mrelationship_list_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# Build the set of relationship types to include\u001b[39;00m\n\u001b[0;32m    239\u001b[0m relationship_types_to_include \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[4], line 26\u001b[0m, in \u001b[0;36mrelationship_list_generator\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmattp\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWork_Related\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSystematic_Trading\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLibrary\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mB_Notebooks\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGLIEF_company_data_pipeline\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGLEIF_Data.db\u001b[39m\u001b[38;5;124m\"\u001b[39m, check_same_thread\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m cursor \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mcursor()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSELECT data FROM Level_2_Tree_Data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m rows \u001b[38;5;241m=\u001b[39m cursor\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: Level_2_Tree_Data"
     ]
    }
   ],
   "source": [
    "ecosystems, dict_leis_graph = graph_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(ecosystems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(ecosystems[7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecosystems_company_only, dict_leis_to_graph_company_only = graph_processor(\n",
    "    include_company_relationships=True,\n",
    "    include_fund_relationships=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(ecosystems_company_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ecosystems:\n",
    "    # Access the second ecosystem (index 1)\n",
    "    eco = ecosystems[7]\n",
    "    \n",
    "    print(f\"\\nEcosystem 2:\")\n",
    "    print(f\"Nodes: {list(eco.nodes())}\")\n",
    "    \n",
    "    for node, attrs in eco.nodes(data=True):\n",
    "        print(f\"\\nNode: {node}\")\n",
    "        print(f\"  Child Relationships:\")\n",
    "        for child_node, relationships_list in attrs.get('child_relationships', {}).items():\n",
    "            for rel in relationships_list:\n",
    "                print(f\"    Child Node: {child_node}\")\n",
    "                for key, value in rel.items():\n",
    "                    print(f\"      {key.replace('_', ' ').title()}: {value}\")\n",
    "        if not attrs.get('child_relationships'):\n",
    "            print(\"    (No child relationships)\")\n",
    "        \n",
    "        print(f\"  Parent Relationships:\")\n",
    "        for parent_node, relationships_list in attrs.get('parent_relationships', {}).items():\n",
    "            for rel in relationships_list:\n",
    "                print(f\"    Parent Node: {parent_node}\")\n",
    "                for key, value in rel.items():\n",
    "                    print(f\"      {key.replace('_', ' ').title()}: {value}\")\n",
    "        if not attrs.get('parent_relationships'):\n",
    "            print(\"    (No parent relationships)\")\n",
    "    \n",
    "    # Visualize the second ecosystem\n",
    "    str_graph_eco = visualize_graph_interactive_html(eco, title='Ecosystem 2 - Interactive Graph')\n",
    "    display_html_in_browser(str_graph_eco)\n",
    "    \n",
    "else:\n",
    "    print(\"No ecosystems found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecosystems_fund_only, dict_leis_to_fund_company_only = graph_processor(\n",
    "    include_company_relationships=False,\n",
    "    include_fund_relationships=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(len(ecosystems_fund_only))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaya = dict_leis_to_graph_company_only[\"Q774KI4AW80FHFW33O61\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ecosystems:\n",
    "    # Access the second ecosystem (index 1)\n",
    "    eco = yaya\n",
    "    \n",
    "    print(f\"\\nEcosystem 2:\")\n",
    "    print(f\"Nodes: {list(eco.nodes())}\")\n",
    "    \n",
    "    for node, attrs in eco.nodes(data=True):\n",
    "        print(f\"\\nNode: {node}\")\n",
    "        print(f\"  Child Relationships:\")\n",
    "        for child_node, relationships_list in attrs.get('child_relationships', {}).items():\n",
    "            for rel in relationships_list:\n",
    "                print(f\"    Child Node: {child_node}\")\n",
    "                for key, value in rel.items():\n",
    "                    print(f\"      {key.replace('_', ' ').title()}: {value}\")\n",
    "        if not attrs.get('child_relationships'):\n",
    "            print(\"    (No child relationships)\")\n",
    "        \n",
    "        print(f\"  Parent Relationships:\")\n",
    "        for parent_node, relationships_list in attrs.get('parent_relationships', {}).items():\n",
    "            for rel in relationships_list:\n",
    "                print(f\"    Parent Node: {parent_node}\")\n",
    "                for key, value in rel.items():\n",
    "                    print(f\"      {key.replace('_', ' ').title()}: {value}\")\n",
    "        if not attrs.get('parent_relationships'):\n",
    "            print(\"    (No parent relationships)\")\n",
    "    \n",
    "    # Visualize the second ecosystem\n",
    "    str_graph_eco = visualize_graph_interactive_html(eco, title='Ecosystem 2 - Interactive Graph')\n",
    "    display_html_in_browser(str_graph_eco)\n",
    "    \n",
    "else:\n",
    "    print(\"No ecosystems found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\B_Notebooks\\GLIEF_company_data_pipeline\\dict_leis_graph.pickle\" , \"wb\") as file:\n",
    "    pickle.dump(dict_leis_graph, file)  # dump the object as a binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\B_Notebooks\\GLIEF_company_data_pipeline\\dict_leis_graph_company_only.pickle\" , \"wb\") as file:\n",
    "    pickle.dump(dict_leis_to_graph_company_only, file)  # dump the object as a binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\B_Notebooks\\GLIEF_company_data_pipeline\\dict_leis_to_fund_company_only.pickle\" , \"wb\") as file:\n",
    "    pickle.dump(dict_leis_to_fund_company_only, file)  # dump the object as a binary file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"logging\"): #if the logging folder doesnt exist in the directory, make it\n",
    "    os.makedirs(\"../logging\")\n",
    "\n",
    "logging.basicConfig(filename = \"logging/Company_Facts_Baseline.log\" , level = logging.DEBUG, format = '%(levelname)s: %(message)s' , filemode = \"w\")\n",
    "\n",
    "if not os.path.exists(\"file_lib\"):\n",
    "    os.makedirs(\"../file_lib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "target_directory = os.path.abspath(os.path.join(current_directory, \"..\", \"..\", \"..\"))\n",
    "sys.path.append(target_directory)\n",
    "\n",
    "from D_Infastructure import System_Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mattp\\\\Work_Related\\\\Systematic_Trading\\\\Library\\\\B_Notebooks\\\\GLIEF_company_data_pipeline\\\\Work_bench'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mattp\\\\Work_Related\\\\Systematic_Trading\\\\Library'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(target_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
