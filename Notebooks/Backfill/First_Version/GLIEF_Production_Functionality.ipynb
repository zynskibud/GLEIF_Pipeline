{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this will be jupyter notebook code for the front end part of the GLEIF code. Will allow people to easily access the data programatically and will be most likely used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json\n",
    "import pickle\n",
    "import flatdict\n",
    "import networkx as nx\n",
    "import re\n",
    "from rapidfuzz import process, fuzz\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "target_directory = os.path.abspath(os.path.join(current_directory, \"..\", \"..\", \"..\"))\n",
    "sys.path.append(target_directory)\n",
    "from D_Infastructure import VIZ_Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will be loaded in from a database but here for now\n",
    "\n",
    "with open(r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\B_Notebooks\\GLIEF_company_data_pipeline\\dict_leis_graph.pickle\" , \"rb\") as file:\n",
    "    dict_leis_graph = pickle.load(file)\n",
    "    \n",
    "with open(r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\B_Notebooks\\GLIEF_company_data_pipeline\\pickled_objs\\df_level_1_data.pickle\" , \"rb\") as file:\n",
    "    df_level_1_data = pickle.load(file)\n",
    "    \n",
    "with open(r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\B_Notebooks\\GLIEF_company_data_pipeline\\pickled_objs\\dict_company_names_leis.pickle\" , \"rb\") as file:\n",
    "    dict_company_names_leis = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GLEIFCompanySearch:\n",
    "            \n",
    "    def expand_abbreviations(self, name):\n",
    "        \"\"\"\n",
    "        Expand common abbreviations in the company name.\n",
    "        \"\"\"\n",
    "        abbreviation_mapping = {\n",
    "            'int': 'international',\n",
    "            'intl': 'international',\n",
    "            'tech': 'technology',\n",
    "            'svc': 'services',\n",
    "            'mfg': 'manufacturing',\n",
    "            'mktg': 'marketing',\n",
    "            'hvac': 'heating ventilation and air conditioning',\n",
    "            'ag': 'agriculture',\n",
    "            'ai': 'artificial intelligence',\n",
    "            # Add more as needed\n",
    "        }\n",
    "        # Split the name into words\n",
    "        words = name.split()\n",
    "        # Replace abbreviations\n",
    "        expanded_words = [abbreviation_mapping.get(word, word) for word in words]\n",
    "        # Join back into a string\n",
    "        return ' '.join(expanded_words)\n",
    "    \n",
    "    def preprocess_name(self, name):\n",
    "        \"\"\"\n",
    "        Preprocess the company name by:\n",
    "        - Removing common suffixes\n",
    "        - Removing punctuation\n",
    "        - Converting to lowercase\n",
    "        - Expanding abbreviations\n",
    "        \"\"\"\n",
    "        # Remove common company suffixes\n",
    "        suffixes = [\n",
    "            'inc', 'llc', 'ltd', 'corp', 'corporation', 'incorporated',\n",
    "            'co', 'company', 'plc', 'limited', 'gmbh', 'sa', 'bv', 'ag', 'oy', 'llp', 'lp'\n",
    "        ]\n",
    "        # Create regex pattern to remove suffixes\n",
    "        suffix_pattern = r'\\b(?:' + '|'.join(suffixes) + r')\\b\\.?'\n",
    "        name = re.sub(suffix_pattern, '', name, flags=re.IGNORECASE)\n",
    "\n",
    "        # Remove punctuation\n",
    "        name = name.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        # Convert to lowercase and strip whitespace\n",
    "        name = name.lower().strip()\n",
    "\n",
    "        # Expand abbreviations\n",
    "        name = self.expand_abbreviations(name)\n",
    "\n",
    "        return name\n",
    "    \n",
    "    def create_company_index(self, list_company_names, index_length=3):\n",
    "        \"\"\"\n",
    "        Preprocess the company names and create an index based on the first `index_length` characters.\n",
    "\n",
    "        Args:\n",
    "            list_company_names (list): List of official company names.\n",
    "            index_length (int): Number of characters to use for indexing (default is 3).\n",
    "\n",
    "        Returns:\n",
    "            original_names (list): List of original company names.\n",
    "            preprocessed_names (list): List of preprocessed company names.\n",
    "            index (dict): Dictionary mapping prefix to list of indices.\n",
    "        \"\"\"\n",
    "        index = defaultdict(list)\n",
    "        original_names = []\n",
    "        preprocessed_names = []\n",
    "\n",
    "        for idx, name in enumerate(list_company_names):\n",
    "            preprocessed = self.preprocess_name(name)\n",
    "            if not preprocessed:\n",
    "                continue  # Skip empty strings after preprocessing\n",
    "            original_names.append(name)\n",
    "            preprocessed_names.append(preprocessed)\n",
    "            prefix = preprocessed[:index_length] if len(preprocessed) >= index_length else preprocessed\n",
    "            index[prefix].append(len(preprocessed_names) - 1)  # Store the index of the name\n",
    "\n",
    "            # Optional: Progress tracking for large datasets\n",
    "            if (idx + 1) % 100000 == 0:\n",
    "                print(f\"Processed {idx + 1} company names.\")\n",
    "\n",
    "        return original_names, preprocessed_names, index\n",
    "        \n",
    "    \n",
    "    def search_companies(self, user_input, original_names, preprocessed_names, index, limit=10, index_length=3):\n",
    "        \"\"\"\n",
    "        Search for companies matching the user_input.\n",
    "\n",
    "        Args:\n",
    "            user_input (str): The input company name to search for.\n",
    "            original_names (list): List of official company names.\n",
    "            preprocessed_names (list): List of preprocessed company names.\n",
    "            index (dict): The company index created by create_company_index.\n",
    "            limit (int): The number of top matches to return.\n",
    "            index_length (int): The length of the prefix used for indexing.\n",
    "\n",
    "        Returns:\n",
    "            list of tuples: Each tuple contains (original_company_name, score)\n",
    "        \"\"\"\n",
    "        if not user_input or not user_input.strip():\n",
    "            return []\n",
    "        \n",
    "        # Preprocess the input\n",
    "        user_input_processed = self.preprocess_name(user_input)\n",
    "\n",
    "        # Determine the prefix\n",
    "        prefix = user_input_processed[:index_length] if len(user_input_processed) >= index_length else user_input_processed\n",
    "\n",
    "        # Retrieve the subset of company indices from the index\n",
    "        possible_indices = index.get(prefix, [])\n",
    "\n",
    "        if not possible_indices:\n",
    "            # If no matches found in the exact prefix, try with a shorter prefix\n",
    "            if len(prefix) > 1:\n",
    "                prefix = prefix[:2]\n",
    "                possible_indices = index.get(prefix, [])\n",
    "\n",
    "        if not possible_indices:\n",
    "            # Further reduce prefix length if necessary\n",
    "            if len(prefix) > 1:\n",
    "                prefix = prefix[:1]\n",
    "                possible_indices = index.get(prefix, [])\n",
    "\n",
    "        if not possible_indices:\n",
    "            # As a fallback, consider searching the entire dataset\n",
    "            # Note: This is not recommended for very large datasets due to performance\n",
    "            # For 2 million entries, it's better to refine the indexing strategy\n",
    "            print(\"No matches found within the indexed prefixes. Consider refining your search or indexing strategy.\")\n",
    "            return []\n",
    "\n",
    "        # Extract preprocessed names for matching\n",
    "        choices = [preprocessed_names[i] for i in possible_indices]\n",
    "        original_choices = [original_names[i] for i in possible_indices]\n",
    "\n",
    "        # Use RapidFuzz's process.extract with token_set_ratio scorer\n",
    "        matches = process.extract(\n",
    "            user_input_processed,\n",
    "            choices,\n",
    "            scorer=fuzz.token_set_ratio,\n",
    "            limit=limit\n",
    "        )\n",
    "\n",
    "        # Map back to original names with scores\n",
    "        results = []\n",
    "        for match, score, match_idx in matches:\n",
    "            original_name = original_choices[match_idx]\n",
    "            results.append( (original_name, score) )\n",
    "\n",
    "        return results\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_company_names = [key for key in dict_company_names_leis.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is what the class will look like\n",
    "class GLEIFAnalysis:\n",
    "    \n",
    "    def __init__(self , bool_every_relationship_type = False , bool_only_companies = False , bool_only_funds = False) -> None:  \n",
    "        self.bool_every_relationship_type = bool_every_relationship_type\n",
    "        self.bool_only_companies = bool_only_companies\n",
    "        self.bool_only_funds = bool_only_funds\n",
    "        \n",
    "        if self.bool_every_relationship_type == True:\n",
    "            str_file_path = r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\B_Notebooks\\GLIEF_company_data_pipeline\\dict_leis_graph.pickle\"\n",
    "            self.dict_leis_graph = self.load_graph_data(str_file_path)\n",
    "            \n",
    "        if self.bool_only_companies == True:\n",
    "            str_file_path = r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\B_Notebooks\\GLIEF_company_data_pipeline\\dict_leis_graph_company_only.pickle\"\n",
    "            self.dict_leis_graph = self.load_graph_data(str_file_path)\n",
    "            \n",
    "        if self.bool_only_funds == True:\n",
    "            str_file_path = r\"C:\\Users\\mattp\\Work_Related\\Systematic_Trading\\Library\\B_Notebooks\\GLIEF_company_data_pipeline\\dict_leis_to_fund_company_only.pickle\"\n",
    "            self.dict_leis_graph = self.load_graph_data(str_file_path)\n",
    "\n",
    "\n",
    "    def load_graph_data(self , str_file_path):\n",
    "        with open(str_file_path, \"rb\") as file:\n",
    "            return pickle.load(file)\n",
    "    \n",
    "    def company_search(self, str_company_name):\n",
    "        obj_gleif_company_search = GLEIFCompanySearch()\n",
    "        list_original_names, list_preprocessed_names, index = obj_gleif_company_search.create_company_index(list_company_names, index_length=3)\n",
    "        matches = obj_gleif_company_search.search_companies(str_company_name, list_original_names, list_preprocessed_names, index, limit=100, index_length=3)\n",
    "        \n",
    "        return matches   \n",
    "    \n",
    "    def helper_interactive_graph_generator(self , graph):\n",
    "        \"\"\"\n",
    "        Function used to automatically generate a graph for a company ecosystem when queried.\n",
    "        \"\"\"\n",
    "        obj_Visualizations = VIZ_Visualizations.Visualizations()\n",
    "        str_html_content = obj_Visualizations.visualize_graph_interactive_html(G = graph)\n",
    "        obj_Visualizations.display_html_in_browser(html_content = str_html_content)\n",
    "        \n",
    "        \n",
    "    def helper_get_node_attributes(self , graph , str_node):\n",
    "        return graph.nodes[str_node]\n",
    "\n",
    "    def search_node(self , df_level_1_data , str_company_name , bool_display_results = False , bool_return_results = False , bool_all_output = False , bool_node_data = False , bool_single_lei_data = False , bool_lei_neighbor_data = False , bool_lei_graph = False):\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        @param: str_company_name - the legal official company name being inputted. So user wants either the meta data for that company, neighboring edges data, graph, or everything.\n",
    "        @bool_display_results - parameter where the user can indicate if they want the data they are accessing to be displayed\n",
    "        @param: bool_all_output - boolean variable indicating whether the user wants the entire graph of the company output\n",
    "        @param: bool_single_lei_data - boolean variable indicating whether the user wants only meta data regarding the company being queried.  \n",
    "        @param: bool_lei_neighbor_data - boolean variable indicating whether the user wants only meta data regarding its direct neighboring companies within its respective company graph. \n",
    "        @param: bool_lei_graph - boolean variable indicating whether the user would like to view the associated company ecosystem graph. \n",
    "        \n",
    "        @call: - \n",
    "        \n",
    "        @return: - \n",
    "        \"\"\"\n",
    "        if bool_all_output:\n",
    "            bool_node_data = True\n",
    "            bool_single_lei_data = True\n",
    "            bool_lei_neighbor_data = True\n",
    "            bool_lei_graph = True\n",
    "        \n",
    "        try:\n",
    "            graph = self.dict_leis_graph[str_company_name]\n",
    "        except KeyError:\n",
    "            print(\"Company not found in database\")\n",
    "            sys.exit()\n",
    "        dict_results = {}  # Dictionary to store results\n",
    "\n",
    "        \n",
    "        if bool_single_lei_data == True:\n",
    "            dict_company_meta_data = json.loads(df_level_1_data[df_level_1_data['data'].str.contains(str_company_name, na=False)].iloc[0]['data'])        \n",
    "            if bool_display_results == True:\n",
    "                print(f\"Showing meta data for {str_company_name}\")\n",
    "                display(dict_company_meta_data)\n",
    "            dict_results['company_meta_data'] = dict_company_meta_data\n",
    "           \n",
    "            \n",
    "        if bool_node_data == True:\n",
    "            dict_attributes = self.helper_get_node_attributes(graph = graph , str_node = str_company_name)\n",
    "            if bool_display_results == True:\n",
    "                print(f\"Displaying attribute data stored at the {str_company_name} node:\")\n",
    "                display(dict_attributes)\n",
    "            dict_results['node_attributes'] = dict_attributes\n",
    "        \n",
    "        if bool_lei_neighbor_data == True:\n",
    "            list_neighbors = list(graph.neighbors(str_company_name))\n",
    "            dict_results[\"neighbors\"] = list_neighbors\n",
    "            if bool_display_results == True:\n",
    "                print(f\"List of neighboring nodes for node {str_company_name}:\")\n",
    "                display(list_neighbors)\n",
    "                for neighbor in list_neighbors:\n",
    "                    print(f\"Displaying attribute data for {neighbor} node:\")\n",
    "                    print(self.helper_get_node_attributes(graph = graph, str_node = neighbor))\n",
    "            \n",
    "        if bool_lei_graph == True:\n",
    "            self.helper_interactive_graph_generator(graph = graph)    \n",
    "        \n",
    "        if bool_return_results == True:\n",
    "            return dict_results\n",
    "        \n",
    "    def check_if_related(self , list_nodes, bool_return_path = False):\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        try:\n",
    "            graph = self.dict_leis_graph[list_nodes[0]]\n",
    "        except KeyError:\n",
    "            print(\"One or more of the nodes which were inputted are do not exist in our database!\")\n",
    "            sys.exit()    \n",
    "        \n",
    "        \n",
    "        for i in range(len(list_nodes) - 1):\n",
    "                list_full_path = []\n",
    "                source = list_nodes[i]\n",
    "                target = list_nodes[i + 1]\n",
    "                if not nx.has_path(graph, source, target):  # Check if path exists\n",
    "                        print(\"There is no path between this group of nodes\")\n",
    "                        return None\n",
    "                path = nx.shortest_path(graph, source=source, target=target)\n",
    "                list_full_path.extend(path[:-1])  # Exclude last node to avoid duplication\n",
    "                list_full_path.append(list_nodes[-1])  # Add the last node\n",
    "                print(f\"There is a path between this group of nodes: {list_full_path}\")\n",
    "                if bool_return_path == True:\n",
    "                        return list_full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"nodes = [\"2138003BXMFSMKRSAA14\", \"254900ZVA3CKR9KO3K08\"]\n",
    "obj_GLIEF_Analysis = GLEIFAnalysis(bool_every_relationship_type = True)\n",
    "obj_GLIEF_Analysis.check_if_related(list_nodes = nodes)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(dict_leis_graph)\n",
    "\"\"\"graph = dict_leis_graph[\"YXV7SD2336DP03R26H81\"]\n",
    "neighbors = list(graph.neighbors(\"5299009PD6KJQQD9BQ74\"))\n",
    "display(neighbors)\n",
    "nodes_list = list(graph.nodes())\n",
    "display(nodes_list)\"\"\"\n",
    "nodes = [\"5299009PD6KJQQD9BQ74\", \"549300RUNVJBS1PI2Y96\"]\n",
    "obj_GLIEF_Analysis = GLEIFAnalysis(bool_every_relationship_type = True)\n",
    "obj_GLIEF_Analysis.check_if_related(list_nodes = nodes)\n",
    "str_node = \"5299009PD6KJQQD9BQ74\"\n",
    "\n",
    "attributes = obj_GLIEF_Analysis.search_node(df_level_1_data = df_level_1_data , bool_lei_neighbor_data = True, bool_node_data = True , str_company_name = str_node , bool_display_results = True)\n",
    "\n",
    "matches = obj_GLIEF_Analysis.company_search(\"Amazon\")\n",
    "display(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_GLIEF_Analysis = GLEIFAnalysis(bool_only_companies = True)\n",
    "obj_GLIEF_Analysis.search_node(df_level_1_data = df_level_1_data , bool_lei_graph = True, str_company_name = \"5299009PD6KJQQD9BQ74\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_GLIEF_Analysis = GLEIFAnalysis(bool_only_companies = True)\n",
    "obj_GLIEF_Analysis.search_node(df_level_1_data = df_level_1_data , bool_single_lei_data = True , str_company_name = \"hjfhj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing meta data for ZXTILKJKG63JELOEG630\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'LEI': {'$': 'ZXTILKJKG63JELOEG630'},\n",
       " 'Entity': {'LegalName': {'@xml:lang': 'en', '$': 'AMAZON.COM, INC.'},\n",
       "  'LegalAddress': {'@xml:lang': 'en',\n",
       "   'FirstAddressLine': {'$': 'C/O CORPORATION SERVICE COMPANY'},\n",
       "   'AdditionalAddressLine': [{'$': '251 LITTLE FALLS DRIVE'}],\n",
       "   'City': {'$': 'WILMINGTON'},\n",
       "   'Region': {'$': 'US-DE'},\n",
       "   'Country': {'$': 'US'},\n",
       "   'PostalCode': {'$': '19808'}},\n",
       "  'HeadquartersAddress': {'@xml:lang': 'en',\n",
       "   'FirstAddressLine': {'$': '410 Terry Ave North'},\n",
       "   'City': {'$': 'Seattle'},\n",
       "   'Region': {'$': 'US-WA'},\n",
       "   'Country': {'$': 'US'},\n",
       "   'PostalCode': {'$': '98109'}},\n",
       "  'RegistrationAuthority': {'RegistrationAuthorityID': {'$': 'RA000602'},\n",
       "   'RegistrationAuthorityEntityID': {'$': '2620453'}},\n",
       "  'LegalJurisdiction': {'$': 'US-DE'},\n",
       "  'EntityCategory': {'$': 'GENERAL'},\n",
       "  'LegalForm': {'EntityLegalFormCode': {'$': 'XTIQ'}},\n",
       "  'EntityStatus': {'$': 'ACTIVE'},\n",
       "  'EntityCreationDate': {'$': '1996-05-28T00:00:00.000Z'}},\n",
       " 'Registration': {'InitialRegistrationDate': {'$': '2012-06-06T15:52:00.000Z'},\n",
       "  'LastUpdateDate': {'$': '2024-10-17T10:16:52.512Z'},\n",
       "  'RegistrationStatus': {'$': 'ISSUED'},\n",
       "  'NextRenewalDate': {'$': '2025-11-07T19:23:00.000Z'},\n",
       "  'ManagingLOU': {'$': '5493001KJTIIGC8Y1R12'},\n",
       "  'ValidationSources': {'$': 'FULLY_CORROBORATED'},\n",
       "  'ValidationAuthority': {'ValidationAuthorityID': {'$': 'RA000602'},\n",
       "   'ValidationAuthorityEntityID': {'$': '2620453'}}},\n",
       " 'Extension': {'gleif:Geocoding': {'gleif:original_address': {'$': '251 LITTLE FALLS DRIVE, 19808, WILMINGTON, US-DE, US'},\n",
       "   'gleif:relevance': {'$': '0.93'},\n",
       "   'gleif:match_type': {'$': 'pointAddress'},\n",
       "   'gleif:lat': {'$': '39.7602'},\n",
       "   'gleif:lng': {'$': '-75.62241'},\n",
       "   'gleif:geocoding_date': {'$': '2017-10-23T01:26:02'},\n",
       "   'gleif:bounding_box': {'$': 'TopLeft.Latitude: 39.7613242, TopLeft.Longitude: -75.6238724, BottomRight.Latitude: 39.7590758, BottomRight.Longitude: -75.6209476'},\n",
       "   'gleif:match_level': {'$': 'houseNumber'},\n",
       "   'gleif:formatted_address': {'$': '251 Little Falls Dr, Wilmington, DE 19808, United States'},\n",
       "   'gleif:mapped_location_id': {'$': 'NT_otquaQ4K0FGaT9Z.yb03SA_yUTM'},\n",
       "   'gleif:mapped_street': {'$': 'Little Falls Dr'},\n",
       "   'gleif:mapped_housenumber': {'$': '251'},\n",
       "   'gleif:mapped_postalcode': {'$': '19808'},\n",
       "   'gleif:mapped_city': {'$': 'Wilmington'},\n",
       "   'gleif:mapped_state': {'$': 'DE'},\n",
       "   'gleif:mapped_country': {'$': 'USA'}},\n",
       "  'gleif:conformity': {'gleif:conformityflag': {'$': 'CONFORMING'}}}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying attribute data stored at the ZXTILKJKG63JELOEG630 node:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'child_relationships': {'5493006K9CUYTRQ9Z556': [{'relationship_type': 'IS_DIRECTLY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2012-06-06T15:52:00.000Z',\n",
       "    'last_update_date': '2024-10-08T17:44:06.864Z',\n",
       "    'next_renewal_date': '2025-10-01T12:41:06.314Z'},\n",
       "   {'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2012-06-06T15:52:00.000Z',\n",
       "    'last_update_date': '2024-10-08T17:44:06.864Z',\n",
       "    'next_renewal_date': '2025-10-01T12:41:06.314Z'}],\n",
       "  '549300CLGXJ3ZDL9PZ27': [{'relationship_type': 'IS_DIRECTLY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2022-11-25T00:00:00Z',\n",
       "    'last_update_date': '2024-09-16T11:31:00Z',\n",
       "    'next_renewal_date': '2024-11-22T09:13:00Z'},\n",
       "   {'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2022-11-25T00:00:00Z',\n",
       "    'last_update_date': '2024-09-16T11:31:00Z',\n",
       "    'next_renewal_date': '2024-11-22T09:13:00Z'}],\n",
       "  '549300FOH8RQYSVCUM62': [{'relationship_type': 'IS_DIRECTLY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'LAPSED',\n",
       "    'initial_registration_date': '2022-07-12T00:00:00Z',\n",
       "    'last_update_date': '2023-08-09T11:39:00Z',\n",
       "    'next_renewal_date': '2023-07-06T23:48:00Z'},\n",
       "   {'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'LAPSED',\n",
       "    'initial_registration_date': '2022-07-12T00:00:00Z',\n",
       "    'last_update_date': '2023-08-09T11:39:00Z',\n",
       "    'next_renewal_date': '2023-07-06T23:48:00Z'}],\n",
       "  '549300HPVQKZ1SHYOI67': [{'relationship_type': 'IS_DIRECTLY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2020-01-24T15:29:00Z',\n",
       "    'last_update_date': '2023-12-14T08:26:03.089Z',\n",
       "    'next_renewal_date': '2024-11-07T19:23:00Z'},\n",
       "   {'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2020-01-24T15:29:00Z',\n",
       "    'last_update_date': '2023-12-14T08:26:03.089Z',\n",
       "    'next_renewal_date': '2024-11-07T19:23:00Z'}],\n",
       "  '549300LC7JL3ZME73B60': [{'relationship_type': 'IS_DIRECTLY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2012-06-06T15:52:00.000Z',\n",
       "    'last_update_date': '2024-10-17T10:16:53.722Z',\n",
       "    'next_renewal_date': '2025-11-07T00:00:00.000Z'},\n",
       "   {'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2012-06-06T15:52:00.000Z',\n",
       "    'last_update_date': '2024-10-17T10:16:53.722Z',\n",
       "    'next_renewal_date': '2025-11-07T00:00:00.000Z'}],\n",
       "  '549300MXYHQ7ZLRMHA29': [{'relationship_type': 'IS_DIRECTLY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2022-09-01T15:29:00.000Z',\n",
       "    'last_update_date': '2024-10-08T17:44:06.910Z',\n",
       "    'next_renewal_date': '2025-10-01T12:41:06.546Z'},\n",
       "   {'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2022-09-01T15:29:00.000Z',\n",
       "    'last_update_date': '2024-10-08T17:44:06.910Z',\n",
       "    'next_renewal_date': '2025-10-01T12:41:06.546Z'}],\n",
       "  '549300U87EPT31R7IG45': [{'relationship_type': 'IS_DIRECTLY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2012-06-06T15:52:00.000Z',\n",
       "    'last_update_date': '2024-10-17T10:16:53.137Z',\n",
       "    'next_renewal_date': '2025-11-07T00:00:00.000Z'},\n",
       "   {'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2012-06-06T15:52:00.000Z',\n",
       "    'last_update_date': '2024-10-17T10:16:53.137Z',\n",
       "    'next_renewal_date': '2025-11-07T00:00:00.000Z'}],\n",
       "  '549300W97LR1HYCU5980': [{'relationship_type': 'IS_DIRECTLY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'LAPSED',\n",
       "    'initial_registration_date': '2021-05-27T15:29:00Z',\n",
       "    'last_update_date': '2024-01-06T11:14:14.323Z',\n",
       "    'next_renewal_date': '2024-01-06T19:10:00Z'},\n",
       "   {'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'LAPSED',\n",
       "    'initial_registration_date': '2021-05-27T15:29:00Z',\n",
       "    'last_update_date': '2024-01-06T11:14:14.323Z',\n",
       "    'next_renewal_date': '2024-01-06T19:10:00Z'}],\n",
       "  '549300X63WD2CQT1M860': [{'relationship_type': 'IS_DIRECTLY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'LAPSED',\n",
       "    'initial_registration_date': '2021-09-28T15:29:00Z',\n",
       "    'last_update_date': '2024-07-18T09:14:15.827Z',\n",
       "    'next_renewal_date': '2024-07-18T17:08:00Z'},\n",
       "   {'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'LAPSED',\n",
       "    'initial_registration_date': '2021-09-28T15:29:00Z',\n",
       "    'last_update_date': '2024-07-18T09:14:15.827Z',\n",
       "    'next_renewal_date': '2024-07-18T17:08:00Z'}],\n",
       "  '2549001PR8T0QQE83L18': [{'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2024-05-20T12:52:09.686Z',\n",
       "    'last_update_date': '2024-05-20T12:52:09.686Z',\n",
       "    'next_renewal_date': '2025-05-20T12:52:09.666Z'}],\n",
       "  '254900LNRYNOQ9YPU758': [{'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2024-05-20T12:52:09.876Z',\n",
       "    'last_update_date': '2024-05-20T12:52:09.876Z',\n",
       "    'next_renewal_date': '2025-05-20T12:52:09.862Z'}],\n",
       "  '5493009SM3CIFF7EXX39': [{'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2020-03-02T15:29:00.000Z',\n",
       "    'last_update_date': '2024-03-27T12:21:34.939Z',\n",
       "    'next_renewal_date': '2025-03-27T12:21:34.924Z'}],\n",
       "  '549300LS9KH1OREMJV62': [{'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'LAPSED',\n",
       "    'initial_registration_date': '2012-06-06T15:52:00Z',\n",
       "    'last_update_date': '2023-11-25T00:11:10Z',\n",
       "    'next_renewal_date': '2023-11-25T00:00:00Z'}],\n",
       "  '549300SD3Q0SSUS5JE17': [{'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'INACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2013-04-16T22:17:00.000Z',\n",
       "    'last_update_date': '2018-03-24T21:48:00.000Z',\n",
       "    'next_renewal_date': '2019-01-24T00:31:00.000Z'}],\n",
       "  '8JA4NT75BITP5LG6P072': [{'relationship_type': 'IS_ULTIMATELY_CONSOLIDATED_BY',\n",
       "    'relationship_status': 'ACTIVE',\n",
       "    'registration_status': 'PUBLISHED',\n",
       "    'initial_registration_date': '2012-06-06T15:52:00.000Z',\n",
       "    'last_update_date': '2024-09-30T18:42:21.958Z',\n",
       "    'next_renewal_date': '2025-10-04T00:00:00.000Z'}]},\n",
       " 'parent_relationships': {}}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of neighboring nodes for neighboring node ZXTILKJKG63JELOEG630:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactive graph 'Interactive_Graph' generated successfully.\n"
     ]
    }
   ],
   "source": [
    "obj_GLIEF_Analysis = GLEIFAnalysis(bool_every_relationship_type= True)\n",
    "dict_results = obj_GLIEF_Analysis.search_node(df_level_1_data = df_level_1_data , bool_display_results= True, bool_all_output = True , str_company_name = \"ZXTILKJKG63JELOEG630\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whats left:\n",
    "1. Cleaning/Modularzing the code as much as possible so We Can use it Anywhere\n",
    "- Clean the graph builder\n",
    "- Modularize the code in this jupyter notebook as much as possible\n",
    "- For the graph loader, add checks for if the graph is too large\n",
    "2. Renaming the lei ids to be the company names as listed on the GLIEF\n",
    "3. Updating the data\n",
    "4. Unit Tests\n",
    "5. Docs\n",
    "6. Code Review\n",
    "7. Get it front ended and working as a functioning pipeline in the server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some GPT ass code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import re\n",
    "from rapidfuzz import process, fuzz\n",
    "from collections import defaultdict\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
